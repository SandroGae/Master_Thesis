{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This dataset could be used to train a 3D CNN with 3D inputs and 3D outputs / 3D ground truth\n",
    "Note: This requires more memory and computiational power\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d89223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from numpy.lib.format import open_memmap\n",
    "\n",
    "# ====== Reading in data ===\n",
    "def load_split(file_path):\n",
    "    with h5py.File(file_path, \"r\") as f:\n",
    "        high = f[\"/high_count/data\"][:].transpose(2, 0, 1)  # (N,H,W)\n",
    "        low  = f[\"/low_count/data\"][:].transpose(2, 0, 1)\n",
    "    return high, low\n",
    "\n",
    "data = {\n",
    "    \"train\": load_split(\"training_data.hdf5\"),\n",
    "    \"test\":  load_split(\"test_data.hdf5\"),\n",
    "    \"val\":   load_split(\"validation_data.hdf5\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b55736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= Normalising Data =================\n",
    "def anscombe_vst(x):\n",
    "    # Negative values get yeeted to zero (counts should not be negative)\n",
    "    x = np.maximum(x, 0)\n",
    "    return 2.0 * np.sqrt(x + 3.0/8.0)\n",
    "\n",
    "def compute_clip_from_high(high_data, percentile=99.9, use_vst=True, max_samples=5_000_000, rng=None):\n",
    "    \"\"\"\n",
    "    From High count data, determine global Clip_values\n",
    "    percentile: e.g. 99.9\n",
    "    use_vst: If True -> Calculate Clip on VSC domain (usually better)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    arr = high_data.ravel()\n",
    "    sample = arr if arr.size <= max_samples else arr[rng.choice(arr.size, size=max_samples, replace=False)]\n",
    "    if use_vst:\n",
    "        sample = anscombe_vst(sample)\n",
    "    clip_val = np.percentile(sample, percentile)\n",
    "    if not np.isfinite(clip_val) or clip_val <= 0:\n",
    "        clip_val = float(np.max(sample))\n",
    "    return float(clip_val)\n",
    "\n",
    "def preprocess_counts(x, clip_val, use_vst=True, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Normalization: optional VST -> clip -> /clip -> [0,1]\n",
    "    \"\"\"\n",
    "    x = anscombe_vst(x) if use_vst else x\n",
    "    x = np.clip(x, 0, clip_val) / clip_val\n",
    "    return x.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95caff00",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os, gc\n",
    "from numpy.lib.format import open_memmap\n",
    "\n",
    "# ================= Build 3D Datasets =================\n",
    "def build_sequential_dataset(low_data, high_data, size, group_len, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Generates training data:\n",
    "      X: (B, size, H, W) = window of `size` Low-Count images\n",
    "      Y: (B, size, H, W) = Ground truth = window of `size` High-Count images (3D output)\n",
    "      N: Number of Pictrues in total\n",
    "      H: Height of each image\n",
    "      W: Width of each image\n",
    "      size: Size of sliding window (must be odd)\n",
    "      group_len: Length of each block (e.g. 41 for training/test/val)\n",
    "    Note: Sliding window is only applied inside each block of length `group_len`\n",
    "    \"\"\"\n",
    "    assert low_data.shape == high_data.shape, \"low/high must have identical shapes\"\n",
    "    N, H, W = low_data.shape\n",
    "    if size % 2 == 0 or size < 1:\n",
    "        raise ValueError(\"`size` must be odd and >= 1 (e.g., 3, 5, 7)\")\n",
    "    if N % group_len != 0:\n",
    "        raise ValueError(f\"N={N} is not a multiple of group_len={group_len}.\")\n",
    "\n",
    "    num_groups = N // group_len\n",
    "    X_list, Y_list = [], []\n",
    "\n",
    "    for group_index in range(num_groups):\n",
    "        start = group_index * group_len\n",
    "        end   = start + group_len\n",
    "        # slide window inside this block only\n",
    "        for n in range(start, end - size + 1):         # stride = 1\n",
    "            X_list.append(low_data[n: n + size])       # (size,H,W)\n",
    "            Y_list.append(high_data[n: n + size])      # (size,H,W)\n",
    "\n",
    "    X = np.stack(X_list, axis=0).astype(dtype)   # (B, size, H, W)\n",
    "    Y = np.stack(Y_list, axis=0).astype(dtype)   # (B, size, H, W)\n",
    "    # Adding Channel-Dimension since PyTorch expects (B,C,D,H,W) with C=1\n",
    "    X = X[:, None, ...]  # (B, 1, size, H, W)\n",
    "    Y = Y[:, None, ...]  # (B, 1, size, H, W)\n",
    "    return X, Y\n",
    "\n",
    "# ===== Applying on (N,H,W) data =====\n",
    "size = 5 # Adjust window size to find best value (e.g. 3,5,7)\n",
    "group_len = 41\n",
    "\n",
    "# === Normalzing Data ===\n",
    "USE_VST = True\n",
    "PCT = 99.9\n",
    "\n",
    "# Speicherort direkt im Projektordner\n",
    "print(\"Das aktuelle Arbeitsverzeichnis ist:\", os.getcwd())\n",
    "outdir = os.path.join(os.getcwd(), \"data_3D_U-net\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "def build_and_save_windows_streaming(low_n, high_n, split_name, outdir,\n",
    "                                     size=5, group_len=41, dtype=np.float32):\n",
    "    assert low_n.shape == high_n.shape\n",
    "    N, H, W = low_n.shape\n",
    "    assert N % group_len == 0, f\"N={N} kein Vielfaches von {group_len}\"\n",
    "    assert size % 2 == 1 and size >= 1\n",
    "\n",
    "    outdir = os.path.normpath(outdir)\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    num_groups    = N // group_len\n",
    "    win_per_group = group_len - size + 1\n",
    "    B             = num_groups * win_per_group\n",
    "\n",
    "    X_path = os.path.join(outdir, f\"X_{split_name}.npy\")\n",
    "    Y_path = os.path.join(outdir, f\"Y_{split_name}.npy\")\n",
    "\n",
    "    # alte Dateien entfernen (falls noch da)\n",
    "    for p in (X_path, Y_path):\n",
    "        if os.path.exists(p):\n",
    "            try:\n",
    "                os.remove(p)\n",
    "            except PermissionError as e:\n",
    "                raise RuntimeError(f\"{p} ist noch gemappt/offen. Schliess alle np.load(..., mmap_mode='r').\") from e\n",
    "\n",
    "    print(\"create:\", repr(X_path), \"and\", repr(Y_path))\n",
    "\n",
    "    X_mm = open_memmap(X_path, mode=\"w+\", dtype=dtype, shape=(B, 1, size, H, W))\n",
    "    Y_mm = open_memmap(Y_path, mode=\"w+\", dtype=dtype, shape=(B, 1, size, H, W))\n",
    "\n",
    "    write_idx = 0\n",
    "    for g in range(num_groups):\n",
    "        s = g * group_len\n",
    "        e = s + group_len\n",
    "        low_blk  = low_n[s:e]\n",
    "        high_blk = high_n[s:e]\n",
    "        for n in range(win_per_group):\n",
    "            X_mm[write_idx, 0] = low_blk[n:n+size]\n",
    "            Y_mm[write_idx, 0] = high_blk[n:n+size]\n",
    "            write_idx += 1\n",
    "        del low_blk, high_blk\n",
    "        gc.collect()\n",
    "\n",
    "    del X_mm, Y_mm\n",
    "    gc.collect()\n",
    "    print(f\"[{split_name}] saved -> shape=({B}, 1, {size}, {H}, {W}), dtype={dtype}\")\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "high_train, low_train = data[\"train\"]  # (high, low)\n",
    "clip_val_train = compute_clip_from_high(high_train, percentile=PCT, use_vst=USE_VST)\n",
    "\n",
    "# ---------- 1) Bauen & Speichern ----------\n",
    "DTYPE_OUT = np.float32  # bei Platznot: np.float16\n",
    "\n",
    "# globaler Clip einmal aus TRAIN\n",
    "high_train, low_train = data[\"train\"]\n",
    "clip_val_train = compute_clip_from_high(high_train, percentile=PCT, use_vst=USE_VST)\n",
    "\n",
    "# evt. offene Memmaps schliessen, bevor wir schreiben\n",
    "try:\n",
    "    del X_vis, Y_vis\n",
    "except NameError:\n",
    "    pass\n",
    "gc.collect()\n",
    "\n",
    "for split in [\"train\", \"test\", \"val\"]:\n",
    "    high_split, low_split = data[split]  # (high, low)\n",
    "\n",
    "    low_n  = preprocess_counts(low_split,  clip_val_train, use_vst=USE_VST, dtype=DTYPE_OUT)\n",
    "    high_n = preprocess_counts(high_split, clip_val_train, use_vst=USE_VST, dtype=DTYPE_OUT)\n",
    "\n",
    "    build_and_save_windows_streaming(low_n, high_n, split, outdir,\n",
    "                                     size=size, group_len=group_len, dtype=DTYPE_OUT)\n",
    "\n",
    "    del low_n, high_n\n",
    "    gc.collect()\n",
    "\n",
    "# ---------- 2) Report (existiert? dann Groesse anzeigen) ----------\n",
    "for split in [\"train\",\"test\",\"val\"]:\n",
    "    for name in [f\"X_{split}.npy\", f\"Y_{split}.npy\"]:\n",
    "        p = os.path.join(outdir, name)\n",
    "        if os.path.exists(p):\n",
    "            print(f\"{name:12} exists=True  size={os.path.getsize(p)//(1024*1024)} MB\")\n",
    "        else:\n",
    "            print(f\"{name:12} exists=False size=0 MB (noch nicht erzeugt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ddefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.format import read_magic, read_array_header_1_0, read_array_header_2_0\n",
    "\n",
    "def npy_info(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        ver = read_magic(f)\n",
    "        if ver == (1, 0):\n",
    "            shape, fortran_order, dtype = read_array_header_1_0(f)\n",
    "        else:\n",
    "            shape, fortran_order, dtype = read_array_header_2_0(f)\n",
    "    return shape, dtype\n",
    "\n",
    "print(\"\\n=== Uebersicht der gespeicherten Dateien ===\")\n",
    "for split in [\"train\", \"test\", \"val\"]:\n",
    "    for name in [f\"X_{split}.npy\", f\"Y_{split}.npy\"]:\n",
    "        p = os.path.join(outdir, name)\n",
    "        shape, dtype = npy_info(p)\n",
    "        size_mb = os.path.getsize(p) / 1024 / 1024\n",
    "        print(f\"{name:12}  shape={shape}, dtype={dtype}, size={size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19bdeaa",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "# ===== Visualization of some samples =====\n",
    "\n",
    "def show_window_pair_3d(X, Y, sample_idx, size=5, group_len=41, share_scale=False):\n",
    "    \"\"\"\n",
    "    Visualizes training sample for 3D:\n",
    "      - Top: Low_Count sequence\n",
    "      - Bottom: High_Count sequence\n",
    "\n",
    "    X: (B, 1, size, H, W)  # Note: 1 is the number of channels (here 1)\n",
    "    Y: (B, 1, size, H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove channel dimension\n",
    "    seq_low = X[sample_idx]    # (1, size, H, W)\n",
    "    seq_high = Y[sample_idx]   # (1, size, H, W)\n",
    "    if seq_low.ndim == 4 and seq_low.shape[0] == 1:\n",
    "        seq_low = seq_low[0]\n",
    "        seq_high = seq_high[0]\n",
    "\n",
    "    k = size // 2\n",
    "    group_idx = sample_idx // (group_len - size + 1)\n",
    "    offset_in_group = sample_idx % (group_len - size + 1)\n",
    "    global_start = group_idx * group_len + offset_in_group\n",
    "    frame_indices = list(range(global_start, global_start + size))\n",
    "\n",
    "    fig, axes = plt.subplots(2, size, figsize=(3 * size, 6))\n",
    "\n",
    "    for j in range(size):\n",
    "        # Low-Count\n",
    "        vmin, vmax = np.percentile(seq_low[j].ravel(), (1, 99))\n",
    "        im_low = axes[0, j].imshow(\n",
    "            seq_low[j], cmap=\"gray_r\", origin=\"lower\",\n",
    "            aspect=\"equal\", vmin=vmin, vmax=vmax\n",
    "        )\n",
    "        axes[0, j].set_title(f\"Low idx={frame_indices[j]}\")\n",
    "        axes[0, j].axis(\"off\")\n",
    "        fig.colorbar(im_low, ax=axes[0, j], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # High-Count\n",
    "        vmin, vmax = np.percentile(seq_high[j].ravel(), (1, 99))\n",
    "        im_high = axes[1, j].imshow(\n",
    "            seq_high[j], cmap=\"gray_r\", origin=\"lower\",\n",
    "            aspect=\"equal\", vmin=vmin, vmax=vmax\n",
    "        )\n",
    "        axes[1, j].set_title(f\"High idx={frame_indices[j]}\")\n",
    "        axes[1, j].axis(\"off\")\n",
    "        fig.colorbar(im_high, ax=axes[1, j], fraction=0.046, pad=0.04)\n",
    "\n",
    "    axes[0, k].set_title(f\"Low idx={frame_indices[k]} (center)\")\n",
    "    axes[1, k].set_title(f\"High idx={frame_indices[k]} (center)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Visualization from saved files ===\n",
    "X_vis = np.load(os.path.join(outdir, \"X_train.npy\"), mmap_mode=\"r\")\n",
    "Y_vis = np.load(os.path.join(outdir, \"Y_train.npy\"), mmap_mode=\"r\")\n",
    "\n",
    "for idx in range(3):\n",
    "    show_window_pair_3d(X_vis, Y_vis, sample_idx=idx, size=size, group_len=group_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
