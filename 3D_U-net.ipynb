{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b250fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sandr\\miniconda3\\envs\\dl\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caeb9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"):\n",
    "    x = layers.Conv3D(filters, kernel_size, padding=padding)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    x = layers.Conv3D(filters, kernel_size, padding=padding)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def unet3d(input_shape=(5, 192, 240, 1), base_filters=32):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder (pool only over H,W)\n",
    "    c1 = conv_block(inputs, base_filters)\n",
    "    p1 = layers.MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2))(c1)\n",
    "\n",
    "    c2 = conv_block(p1, base_filters*2)\n",
    "    p2 = layers.MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2))(c2)\n",
    "\n",
    "    c3 = conv_block(p2, base_filters*4)\n",
    "    p3 = layers.MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2))(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    bn = conv_block(p3, base_filters*8)\n",
    "\n",
    "    # Decoder (upsample only over H,W)\n",
    "    u3 = layers.Conv3DTranspose(base_filters*4, kernel_size=(1,2,2), strides=(1,2,2), padding=\"same\")(bn)\n",
    "    u3 = layers.concatenate([u3, c3])\n",
    "    c4 = conv_block(u3, base_filters*4)\n",
    "\n",
    "    u2 = layers.Conv3DTranspose(base_filters*2, kernel_size=(1,2,2), strides=(1,2,2), padding=\"same\")(c4)\n",
    "    u2 = layers.concatenate([u2, c2])\n",
    "    c5 = conv_block(u2, base_filters*2)\n",
    "\n",
    "    u1 = layers.Conv3DTranspose(base_filters, kernel_size=(1,2,2), strides=(1,2,2), padding=\"same\")(c5)\n",
    "    u1 = layers.concatenate([u1, c1])\n",
    "    c6 = conv_block(u1, base_filters)\n",
    "\n",
    "    outputs = layers.Conv3D(1, (1,1,1), activation=\"linear\")(c6)\n",
    "    return models.Model(inputs, outputs, name=\"3D_U-Net\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa72322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sandr\\miniconda3\\envs\\dl\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\sandr\\miniconda3\\envs\\dl\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"3D_U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 5, 192, 240, 1)]     0         []                            \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)             (None, 5, 192, 240, 16)      448       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 5, 192, 240, 16)      64        ['conv3d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 5, 192, 240, 16)      0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)           (None, 5, 192, 240, 16)      6928      ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 5, 192, 240, 16)      64        ['conv3d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 5, 192, 240, 16)      0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3  (None, 5, 96, 120, 16)       0         ['activation_1[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)           (None, 5, 96, 120, 32)       13856     ['max_pooling3d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 5, 96, 120, 32)       128       ['conv3d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 5, 96, 120, 32)       0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)           (None, 5, 96, 120, 32)       27680     ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 5, 96, 120, 32)       128       ['conv3d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 5, 96, 120, 32)       0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPoolin  (None, 5, 48, 60, 32)        0         ['activation_3[0][0]']        \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)           (None, 5, 48, 60, 64)        55360     ['max_pooling3d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 5, 48, 60, 64)        256       ['conv3d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 5, 48, 60, 64)        0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)           (None, 5, 48, 60, 64)        110656    ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 5, 48, 60, 64)        256       ['conv3d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 5, 48, 60, 64)        0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPoolin  (None, 5, 24, 30, 64)        0         ['activation_5[0][0]']        \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)           (None, 5, 24, 30, 128)       221312    ['max_pooling3d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 5, 24, 30, 128)       512       ['conv3d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 5, 24, 30, 128)       0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)           (None, 5, 24, 30, 128)       442496    ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 5, 24, 30, 128)       512       ['conv3d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 5, 24, 30, 128)       0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv3d_transpose (Conv3DTr  (None, 5, 48, 60, 64)        32832     ['activation_7[0][0]']        \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 5, 48, 60, 128)       0         ['conv3d_transpose[0][0]',    \n",
      "                                                                     'activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)           (None, 5, 48, 60, 64)        221248    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 5, 48, 60, 64)        256       ['conv3d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 5, 48, 60, 64)        0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)           (None, 5, 48, 60, 64)        110656    ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 5, 48, 60, 64)        256       ['conv3d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 5, 48, 60, 64)        0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_1 (Conv3D  (None, 5, 96, 120, 32)       8224      ['activation_9[0][0]']        \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 5, 96, 120, 64)       0         ['conv3d_transpose_1[0][0]',  \n",
      " )                                                                   'activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)          (None, 5, 96, 120, 32)       55328     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 5, 96, 120, 32)       128       ['conv3d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 5, 96, 120, 32)       0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)          (None, 5, 96, 120, 32)       27680     ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 5, 96, 120, 32)       128       ['conv3d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 5, 96, 120, 32)       0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv3d_transpose_2 (Conv3D  (None, 5, 192, 240, 16)      2064      ['activation_11[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 5, 192, 240, 32)      0         ['conv3d_transpose_2[0][0]',  \n",
      " )                                                                   'activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)          (None, 5, 192, 240, 16)      13840     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 5, 192, 240, 16)      64        ['conv3d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 5, 192, 240, 16)      0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)          (None, 5, 192, 240, 16)      6928      ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 5, 192, 240, 16)      64        ['conv3d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 5, 192, 240, 16)      0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)          (None, 5, 192, 240, 1)       17        ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1360369 (5.19 MB)\n",
      "Trainable params: 1358961 (5.18 MB)\n",
      "Non-trainable params: 1408 (5.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\sandr\\miniconda3\\envs\\dl\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\sandr\\miniconda3\\envs\\dl\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "740/740 [==============================] - ETA: 0s - loss: 0.0115 - mae: 0.0529\n",
      "Epoch 1: val_loss improved from inf to 0.00279, saving model to c:\\Users\\sandr\\VS_Master_Thesis\\checkpoints_3d_unet\\best.keras\n",
      "740/740 [==============================] - 669s 901ms/step - loss: 0.0115 - mae: 0.0529 - val_loss: 0.0028 - val_mae: 0.0309 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 0.0021 - mae: 0.0292\n",
      "Epoch 2: val_loss improved from 0.00279 to 0.00213, saving model to c:\\Users\\sandr\\VS_Master_Thesis\\checkpoints_3d_unet\\best.keras\n",
      "740/740 [==============================] - 655s 885ms/step - loss: 0.0021 - mae: 0.0292 - val_loss: 0.0021 - val_mae: 0.0250 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 0.0018 - mae: 0.0270\n",
      "Epoch 3: val_loss improved from 0.00213 to 0.00159, saving model to c:\\Users\\sandr\\VS_Master_Thesis\\checkpoints_3d_unet\\best.keras\n",
      "740/740 [==============================] - 655s 885ms/step - loss: 0.0018 - mae: 0.0270 - val_loss: 0.0016 - val_mae: 0.0218 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 0.0017 - mae: 0.0258\n",
      "Epoch 4: val_loss did not improve from 0.00159\n",
      "740/740 [==============================] - 656s 886ms/step - loss: 0.0017 - mae: 0.0258 - val_loss: 0.0044 - val_mae: 0.0246 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 0.0015 - mae: 0.0246\n",
      "Epoch 5: val_loss improved from 0.00159 to 0.00153, saving model to c:\\Users\\sandr\\VS_Master_Thesis\\checkpoints_3d_unet\\best.keras\n",
      "740/740 [==============================] - 656s 886ms/step - loss: 0.0015 - mae: 0.0246 - val_loss: 0.0015 - val_mae: 0.0227 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0236\n",
      "Epoch 6: val_loss improved from 0.00153 to 0.00084, saving model to c:\\Users\\sandr\\VS_Master_Thesis\\checkpoints_3d_unet\\best.keras\n",
      "740/740 [==============================] - 655s 886ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 8.3575e-04 - val_mae: 0.0191 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0232\n",
      "Epoch 7: val_loss did not improve from 0.00084\n",
      "740/740 [==============================] - 655s 885ms/step - loss: 0.0013 - mae: 0.0232 - val_loss: 0.0014 - val_mae: 0.0260 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0221\n",
      "Epoch 8: val_loss did not improve from 0.00084\n",
      "740/740 [==============================] - 655s 885ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.0020 - val_mae: 0.0324 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0208\n",
      "Epoch 9: val_loss did not improve from 0.00084\n",
      "740/740 [==============================] - 655s 886ms/step - loss: 0.0010 - mae: 0.0208 - val_loss: 0.0012 - val_mae: 0.0230 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0205\n",
      "Epoch 10: val_loss did not improve from 0.00084\n",
      "740/740 [==============================] - 651s 880ms/step - loss: 0.0010 - mae: 0.0205 - val_loss: 0.0011 - val_mae: 0.0251 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 8.8651e-04 - mae: 0.0194\n",
      "Epoch 11: val_loss did not improve from 0.00084\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "740/740 [==============================] - 667s 902ms/step - loss: 8.8651e-04 - mae: 0.0194 - val_loss: 0.0014 - val_mae: 0.0303 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 7.1236e-04 - mae: 0.0170\n",
      "Epoch 12: val_loss did not improve from 0.00084\n",
      "740/740 [==============================] - 668s 903ms/step - loss: 7.1236e-04 - mae: 0.0170 - val_loss: 0.0015 - val_mae: 0.0304 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 6.6449e-04 - mae: 0.0164\n",
      "Epoch 13: val_loss improved from 0.00084 to 0.00076, saving model to c:\\Users\\sandr\\VS_Master_Thesis\\checkpoints_3d_unet\\best.keras\n",
      "740/740 [==============================] - 666s 900ms/step - loss: 6.6449e-04 - mae: 0.0164 - val_loss: 7.6360e-04 - val_mae: 0.0165 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 6.4767e-04 - mae: 0.0162\n",
      "Epoch 14: val_loss did not improve from 0.00076\n",
      "740/740 [==============================] - 654s 884ms/step - loss: 6.4767e-04 - mae: 0.0162 - val_loss: 0.0018 - val_mae: 0.0341 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 6.1512e-04 - mae: 0.0158\n",
      "Epoch 15: val_loss did not improve from 0.00076\n",
      "740/740 [==============================] - 666s 900ms/step - loss: 6.1512e-04 - mae: 0.0158 - val_loss: 7.8728e-04 - val_mae: 0.0177 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "740/740 [==============================] - ETA: 0s - loss: 5.9127e-04 - mae: 0.0152"
     ]
    }
   ],
   "source": [
    "# Pfade\n",
    "DATA_DIR   = os.path.join(os.getcwd(), \"data\", \"data_3D_U-net\")  # Ordner mit X_*.npy / Y_*.npy\n",
    "INPUT_SHAPE = (5, 192, 240, 1)   # NDHWC\n",
    "BATCH_SIZE  = 4\n",
    "EPOCHS      = 100\n",
    "AUTO        = tf.data.AUTOTUNE\n",
    "\n",
    "# GPU Memory Growth (optional)\n",
    "for g in tf.config.list_physical_devices('GPU'):\n",
    "    try: tf.config.experimental.set_memory_growth(g, True)\n",
    "    except: pass\n",
    "\n",
    "# NPY memmap laden (keine Kopie in RAM)\n",
    "def load_split(split):\n",
    "    x = np.load(os.path.join(DATA_DIR, f\"X_{split}.npy\"), mmap_mode=\"r\")\n",
    "    y = np.load(os.path.join(DATA_DIR, f\"Y_{split}.npy\"), mmap_mode=\"r\")\n",
    "    assert x.shape[1:] == INPUT_SHAPE and y.shape[1:] == INPUT_SHAPE\n",
    "    return x, y\n",
    "\n",
    "X_train, Y_train = load_split(\"train\")\n",
    "X_val,   Y_val   = load_split(\"val\")\n",
    "X_test,  Y_test  = load_split(\"test\")\n",
    "\n",
    "# tf.data Pipeline (Index -> numpy_function -> Batch)\n",
    "def make_ds(X_mm, Y_mm, shuffle=True):\n",
    "    n = X_mm.shape[0]\n",
    "    idx = np.arange(n)\n",
    "\n",
    "    def _fetch(i):\n",
    "        i = int(i)\n",
    "        return X_mm[i], Y_mm[i]  # je (5,192,240,1) float32\n",
    "\n",
    "    def tf_fetch(i):\n",
    "        x, y = tf.numpy_function(_fetch, [i], [tf.float32, tf.float32])\n",
    "        x.set_shape(INPUT_SHAPE); y.set_shape(INPUT_SHAPE)\n",
    "        return x, y\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(idx)\n",
    "    if shuffle: ds = ds.shuffle(min(8000, n), reshuffle_each_iteration=True)\n",
    "    ds = ds.map(tf_fetch, num_parallel_calls=AUTO)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_ds(X_train, Y_train, shuffle=True)\n",
    "val_ds   = make_ds(X_val,   Y_val,   shuffle=False)\n",
    "test_ds  = make_ds(X_test,  Y_test,  shuffle=False)\n",
    "\n",
    "# === dein Modell wiederverwenden ===\n",
    "model = unet3d(input_shape=INPUT_SHAPE, base_filters=16)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=\"mse\", metrics=[\"mae\"])\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "ckpt_dir = os.path.join(os.getcwd(), \"checkpoints_3d_unet\"); os.makedirs(ckpt_dir, exist_ok=True)\n",
    "cbs = [\n",
    "    callbacks.ModelCheckpoint(os.path.join(ckpt_dir, \"best.keras\"),\n",
    "                              monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
    "    callbacks.EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True, verbose=1),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6, verbose=1),\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=cbs, verbose=1)\n",
    "\n",
    "# Test\n",
    "res = model.evaluate(test_ds, verbose=1)\n",
    "print(dict(zip(model.metrics_names, res)))\n",
    "\n",
    "# Kurzcheck Prediction-Shape\n",
    "for xb, yb in test_ds.take(1):\n",
    "    yhat = model.predict(xb, verbose=0)\n",
    "    print(\"xb:\", xb.shape, \"yb:\", yb.shape, \"yhat:\", yhat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Hilfsfunktion, um Vorhersagen & Targets als Numpy-Arrays zu holen\n",
    "def collect_preds_and_targets(model, dataset, max_batches=None):\n",
    "    y_true, y_pred = [], []\n",
    "    for b, (xb, yb) in enumerate(dataset):\n",
    "        yhat = model.predict(xb, verbose=0)\n",
    "        y_true.append(yb.numpy())\n",
    "        y_pred.append(yhat)\n",
    "        if max_batches and b >= max_batches - 1:\n",
    "            break\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    return y_true, y_pred\n",
    "\n",
    "# Vorhersagen einsammeln\n",
    "Y_true, Y_pred = collect_preds_and_targets(model, test_ds)\n",
    "\n",
    "# Flatten -> 1D-Vektoren (für Metriken wie R² oder SSIM pro Pixel)\n",
    "yt = Y_true.ravel()\n",
    "yp = Y_pred.ravel()\n",
    "\n",
    "# 1) Klassische Fehler-Metriken\n",
    "mse  = np.mean((yt - yp) ** 2)\n",
    "mae  = np.mean(np.abs(yt - yp))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# 2) R² Score\n",
    "r2 = r2_score(yt, yp)\n",
    "\n",
    "# 3) PSNR (Peak Signal-to-Noise Ratio)\n",
    "psnr = tf.image.psnr(Y_true, Y_pred, max_val=1.0).numpy().mean()\n",
    "\n",
    "# 4) SSIM (Structural Similarity Index)\n",
    "# Achtung: SSIM ist für 2D-Bilder – hier wenden wir es sliceweise an\n",
    "Y_true_2d = Y_true[:, 2, :, :, :]   # mittlerer Slice aus dem 5er-Block\n",
    "Y_pred_2d = Y_pred[:, 2, :, :, :]\n",
    "ssim = tf.image.ssim(Y_true_2d, Y_pred_2d, max_val=1.0).numpy().mean()\n",
    "\n",
    "print(\"=== Evaluation on Test Set ===\")\n",
    "print(f\"MSE   : {mse:.6f}\")\n",
    "print(f\"MAE   : {mae:.6f}\")\n",
    "print(f\"RMSE  : {rmse:.6f}\")\n",
    "print(f\"R²    : {r2:.6f}\")\n",
    "print(f\"PSNR  : {psnr:.2f} dB\")\n",
    "print(f\"SSIM  : {ssim:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
