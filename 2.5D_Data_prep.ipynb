{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cec729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This dataset could be used to either train a 2.5D CNN that uses the different low count pictures as channels\n",
    "Or it could be used to train a CNN model with 3D inputs and 2D outputs / 2D ground truth (simply using 3D kernels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"test_data.hdf5\"\n",
    "\n",
    "with h5py.File(file_path, \"r\") as f:\n",
    "    high_data = f[\"/high_count/data\"][:]   # (192, 240, 3034)\n",
    "    low_data = f[\"/low_count/data\"][:]     # (192, 240, 3034)\n",
    "\n",
    "# Transpose: Matlab --> Python\n",
    "high_data = high_data.transpose(2, 0, 1)   # (3034, 192, 240)\n",
    "low_data = low_data.transpose(2, 0, 1)     # (3034, 192, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anscombe_vst(x):\n",
    "    # Negative values get yeeted to zero (counts should not be negative)\n",
    "    x = np.maximum(x, 0)\n",
    "    return 2.0 * np.sqrt(x + 3.0/8.0)\n",
    "\n",
    "def compute_clip_from_high(high_data, percentile=99.9, use_vst=True, max_samples=5_000_000, rng=None):\n",
    "    \"\"\"\n",
    "    From High count data, determine global Clip_values\n",
    "    percentile: e.g. 99.9\n",
    "    use_vst: If True -> Calculate Clip on VSC domain (usually better)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    arr = high_data.ravel()\n",
    "\n",
    "    if arr.size > max_samples:\n",
    "        idx = rng.choice(arr.size, size=max_samples, replace=False)\n",
    "        sample = arr[idx]\n",
    "    else:\n",
    "        sample = arr\n",
    "\n",
    "    if use_vst:\n",
    "        sample = anscombe_vst(sample) # Only for estimation of clip_val\n",
    "\n",
    "    clip_val = np.percentile(sample, percentile)\n",
    "    if not np.isfinite(clip_val) or clip_val <= 0:\n",
    "        clip_val = float(np.max(sample))\n",
    "    return float(clip_val)\n",
    "\n",
    "def preprocess_counts(x, clip_val, use_vst=True, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Normalization: optional VST -> clip -> /clip -> [0,1]\n",
    "    \"\"\"\n",
    "    x = anscombe_vst(x) if use_vst else x\n",
    "    x = np.clip(x, 0, clip_val) / clip_val\n",
    "    return x.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb2eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequential_dataset(low_data, high_data, size, group_len, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Generates training data:\n",
    "      X: (B, size, H, W) = window of `size` Low-Count images\n",
    "      Y: (B, H, W)       = Ground truth = middle High-Count image of the window\n",
    "    \"\"\"\n",
    "    assert low_data.shape == high_data.shape, \"low/high must have identical shapes\"\n",
    "    N, H, W = low_data.shape\n",
    "\n",
    "    if size % 2 == 0 or size < 1:\n",
    "        raise ValueError(\"`size` must be odd and >= 1 (e.g., 3, 5, 7)\")\n",
    "    if N % group_len != 0:\n",
    "        raise ValueError(f\"N={N} is not a multiple of group_len={group_len}.\")\n",
    "\n",
    "    k = size // 2       # Index for middle of window\n",
    "    num_groups = N // group_len\n",
    "\n",
    "    X_list, Y_list = [], []\n",
    "\n",
    "    for group_index in range(num_groups):\n",
    "        start = group_index * group_len\n",
    "        end   = start + group_len\n",
    "        # slide window inside this block only\n",
    "        for n in range(start, end - size + 1):\n",
    "            seq_win    = low_data[n : n + size]   # (size, H, W)\n",
    "            center_idx = n + k                    # middle frame index\n",
    "            target     = high_data[center_idx]    # (H, W)\n",
    "            X_list.append(seq_win)\n",
    "            Y_list.append(target)\n",
    "\n",
    "    X = np.stack(X_list, axis=0).astype(dtype)   # (B, size, H, W)\n",
    "    Y = np.stack(Y_list, axis=0).astype(dtype)   # (B, H, W)\n",
    "    return X, Y\n",
    "\n",
    "# ===== Applying on loaded (N,H,W) data =====\n",
    "size = 5 # Adjust to find best value (e.g. 3,5,7)\n",
    "group_len = 41\n",
    "\n",
    "# === Normalisierung ===\n",
    "USE_VST = True\n",
    "PCT = 99.9\n",
    "\n",
    "clip_val = compute_clip_from_high(high_data, percentile=PCT, use_vst=USE_VST)\n",
    "\n",
    "low_data_n  = preprocess_counts(low_data,  clip_val, use_vst=USE_VST)\n",
    "high_data_n = preprocess_counts(high_data, clip_val, use_vst=USE_VST)\n",
    "\n",
    "# Dann wie gewohnt:\n",
    "X, Y = build_sequential_dataset(low_data_n, high_data_n, size, group_len, dtype=np.float32)\n",
    "\n",
    "print(\"X shape (B, size, H, W):\", X.shape)\n",
    "print(\"Y shape (B, H, W):     \", Y.shape)\n",
    "\n",
    "# ---- Sanity check ----\n",
    "b0_start = 0\n",
    "k = size // 2\n",
    "\n",
    "seq0 = X[0]                  # (size,H,W) -> should be low_data_n[0:size]\n",
    "gt0  = Y[0]                  # (H,W)      -> should be high_data_n[k]\n",
    "\n",
    "# Comparing arrays\n",
    "print(\"Seq == low_n[0:5]:\",\n",
    "      np.allclose(seq0, low_data_n[0:size]))\n",
    "print(\"GT  == high_n[k]:\",\n",
    "      np.allclose(gt0,  high_data_n[b0_start + k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ecf2e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ===== Visualization of some samples =====\n",
    "\n",
    "def show_window_plus_gt(X, Y, sample_idx, size=5, share_scale=False, group_len=41):\n",
    "    \"\"\"\n",
    "    Shows training data samle (low count pictures) + ground truth (high count picture).\n",
    "    sample_idx: Index in X/Y\n",
    "    \"\"\"\n",
    "    sequence = X[sample_idx]   # (size,H,W)\n",
    "    gt  = Y[sample_idx]   # (H,W)\n",
    "\n",
    "    k = size // 2       # Index for middle of window\n",
    "    group_idx = sample_idx // (group_len - size + 1)\n",
    "    offset_in_group = sample_idx % (group_len - size + 1)\n",
    "    global_start = group_idx * group_len + offset_in_group\n",
    "    frame_indices = list(range(global_start, global_start + size))\n",
    "    gt_index = global_start + k\n",
    "\n",
    "    # Plotting low count pictures (window)\n",
    "    fig, axes = plt.subplots(1, size + 1, figsize=(3*(size+1), 3))\n",
    "    for j in range(size):\n",
    "        vmin, vmax = np.percentile( sequence[j].ravel(), (1, 99))\n",
    "        im = axes[j].imshow( sequence[j], cmap=\"gray_r\", origin=\"lower\", aspect=\"equal\",\n",
    "                            vmin=vmin, vmax=vmax)\n",
    "        axes[j].set_title(f\"Low (idx={frame_indices[j]})\")\n",
    "        axes[j].axis(\"off\")\n",
    "        cbar = fig.colorbar(im, ax=axes[j], fraction=0.046, pad=0.04)\n",
    "        cbar.set_label(\"Intensity\")\n",
    "\n",
    "    # Plotting high count picture\n",
    "    vmin, vmax = np.percentile(gt.ravel(), (1, 99))\n",
    "    im_gt = axes[-1].imshow(gt, cmap=\"gray_r\", origin=\"lower\", aspect=\"equal\",\n",
    "                            vmin=vmin, vmax=vmax)\n",
    "    axes[-1].set_title(f\"High [GT] (idx={gt_index})\")\n",
    "    axes[-1].axis(\"off\")\n",
    "    cbar = fig.colorbar(im_gt, ax=axes[-1], fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"Intensity\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some samples\n",
    "for idx in range(0, 4):\n",
    "    show_window_plus_gt(X, Y, sample_idx=idx, share_scale=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
